{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fba52e6",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url \n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank \n",
    "B) Name \n",
    "C) Artist \n",
    "D) Upload date \n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321d977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: \"Baby Shark Dance\"[7]\n",
      "Name: Pinkfong Baby Shark - Kids' Songs & Stories\n",
      "Artist: 14.32\n",
      "Upload Date: [A]\n",
      "Views: June 17, 2016\n",
      "\n",
      "Rank: \"Despacito\"[10]\n",
      "Name: Luis Fonsi\n",
      "Artist: 8.41\n",
      "Upload Date: [B]\n",
      "Views: January 12, 2017\n",
      "\n",
      "Rank: \"Johny Johny Yes Papa\"[18]\n",
      "Name: LooLoo Kids - Nursery Rhymes and Children's Songs\n",
      "Artist: 6.89\n",
      "Upload Date: \n",
      "Views: October 8, 2016\n",
      "\n",
      "Rank: \"Bath Song\"[19]\n",
      "Name: Cocomelon - Nursery Rhymes\n",
      "Artist: 6.66\n",
      "Upload Date: \n",
      "Views: May 2, 2018\n",
      "\n",
      "Rank: \"Shape of You\"[20]\n",
      "Name: Ed Sheeran\n",
      "Artist: 6.23\n",
      "Upload Date: [C]\n",
      "Views: January 30, 2017\n",
      "\n",
      "Rank: \"See You Again\"[23]\n",
      "Name: Wiz Khalifa\n",
      "Artist: 6.22\n",
      "Upload Date: [D]\n",
      "Views: April 6, 2015\n",
      "\n",
      "Rank: \"Wheels on the Bus\"[28]\n",
      "Name: Cocomelon - Nursery Rhymes\n",
      "Artist: 6.01\n",
      "Upload Date: \n",
      "Views: May 24, 2018\n",
      "\n",
      "Rank: \"Phonics Song with Two Words\"[29]\n",
      "Name: ChuChu TV Nursery Rhymes & Kids Songs\n",
      "Artist: 5.75\n",
      "Upload Date: \n",
      "Views: March 6, 2014\n",
      "\n",
      "Rank: \"Uptown Funk\"[30]\n",
      "Name: Mark Ronson\n",
      "Artist: 5.18\n",
      "Upload Date: \n",
      "Views: November 19, 2014\n",
      "\n",
      "Rank: \"Gangnam Style\"[31]\n",
      "Name: Psy\n",
      "Artist: 5.10\n",
      "Upload Date: [E]\n",
      "Views: July 15, 2012\n",
      "\n",
      "Rank: \"Learning Colors – Colorful Eggs on a Farm\"[36]\n",
      "Name: Miroshka TV\n",
      "Artist: 5.09\n",
      "Upload Date: \n",
      "Views: February 27, 2018\n",
      "\n",
      "Rank: \"Dame Tu Cosita\"[37]\n",
      "Name: Ultra Records\n",
      "Artist: 4.59\n",
      "Upload Date: \n",
      "Views: April 5, 2018\n",
      "\n",
      "Rank: \"Masha and the Bear – Recipe for Disaster\"[38]\n",
      "Name: Get Movies\n",
      "Artist: 4.57\n",
      "Upload Date: \n",
      "Views: January 31, 2012\n",
      "\n",
      "Rank: \"Axel F\"[39]\n",
      "Name: Crazy Frog\n",
      "Artist: 4.45\n",
      "Upload Date: \n",
      "Views: June 16, 2009\n",
      "\n",
      "Rank: \"Sugar\"[40]\n",
      "Name: Maroon 5\n",
      "Artist: 4.02\n",
      "Upload Date: \n",
      "Views: January 14, 2015\n",
      "\n",
      "Rank: \"Baa Baa Black Sheep\"[41]\n",
      "Name: Cocomelon - Nursery Rhymes\n",
      "Artist: 4.01\n",
      "Upload Date: \n",
      "Views: June 25, 2018\n",
      "\n",
      "Rank: \"Counting Stars\"[42]\n",
      "Name: OneRepublic\n",
      "Artist: 4.00\n",
      "Upload Date: \n",
      "Views: May 31, 2013\n",
      "\n",
      "Rank: \"Lakdi Ki Kathi\"[43]\n",
      "Name: Jingle Toons\n",
      "Artist: 3.98\n",
      "Upload Date: \n",
      "Views: June 14, 2018\n",
      "\n",
      "Rank: \"Roar\"[44]\n",
      "Name: Katy Perry\n",
      "Artist: 3.98\n",
      "Upload Date: \n",
      "Views: September 5, 2013\n",
      "\n",
      "Rank: \"Waka Waka (This Time for Africa)\"[45]\n",
      "Name: Shakira\n",
      "Artist: 3.89\n",
      "Upload Date: \n",
      "Views: June 4, 2010\n",
      "\n",
      "Rank: \"Sorry\"[46]\n",
      "Name: Justin Bieber\n",
      "Artist: 3.78\n",
      "Upload Date: \n",
      "Views: October 22, 2015\n",
      "\n",
      "Rank: \"Shree Hanuman Chalisa\"[47]\n",
      "Name: T-Series Bhakti Sagar\n",
      "Artist: 3.77\n",
      "Upload Date: \n",
      "Views: May 10, 2011\n",
      "\n",
      "Rank: \"Humpty the train on a fruits ride\"[48]\n",
      "Name: Kiddiestv Hindi - Nursery Rhymes & Kids Songs\n",
      "Artist: 3.76\n",
      "Upload Date: \n",
      "Views: January 26, 2018\n",
      "\n",
      "Rank: \"Thinking Out Loud\"[49]\n",
      "Name: Ed Sheeran\n",
      "Artist: 3.75\n",
      "Upload Date: \n",
      "Views: October 7, 2014\n",
      "\n",
      "Rank: \"Perfect\"[50]\n",
      "Name: Ed Sheeran\n",
      "Artist: 3.70\n",
      "Upload Date: \n",
      "Views: November 9, 2017\n",
      "\n",
      "Rank: \"Dark Horse\"[51]\n",
      "Name: Katy Perry\n",
      "Artist: 3.70\n",
      "Upload Date: \n",
      "Views: February 20, 2014\n",
      "\n",
      "Rank: \"Let Her Go\"[52]\n",
      "Name: Passenger\n",
      "Artist: 3.64\n",
      "Upload Date: \n",
      "Views: July 25, 2012\n",
      "\n",
      "Rank: \"Faded\"[53]\n",
      "Name: Alan Walker\n",
      "Artist: 3.60\n",
      "Upload Date: \n",
      "Views: December 3, 2015\n",
      "\n",
      "Rank: \"Girls Like You\"[54]\n",
      "Name: Maroon 5\n",
      "Artist: 3.58\n",
      "Upload Date: \n",
      "Views: May 31, 2018\n",
      "\n",
      "Rank: \"Lean On\"[55]\n",
      "Name: Major Lazer Official\n",
      "Artist: 3.57\n",
      "Upload Date: \n",
      "Views: March 22, 2015\n",
      "\n",
      "An unexpected error occurred: list index out of range\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_most_viewed_videos(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad status codes\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', class_='wikitable')\n",
    "        rows = table.find_all('tr')[1:]\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            rank = cells[0].text.strip()\n",
    "            name = cells[1].text.strip()\n",
    "            artist = cells[2].text.strip()\n",
    "            upload_date = cells[4].text.strip()\n",
    "            views = cells[3].text.strip()\n",
    "            print(f\"Rank: {rank}\\nName: {name}\\nArtist: {artist}\\nUpload Date: {upload_date}\\nViews: {views}\\n\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred during the request: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "scrape_most_viewed_videos(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a145140",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/. \n",
    "You need to find following details: \n",
    "A) Series \n",
    "B) Place \n",
    "C) Date \n",
    "D) Time \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a51fbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fixtures found: 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the fixtures page\n",
    "url = \"https://www.bcci.tv/fixtures?platform=international&type=men\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find all fixtures\n",
    "    fixtures = soup.find_all(\"div\", class_=\"js-list\")\n",
    "    \n",
    "    print(\"Number of fixtures found:\", len(fixtures))  # Print the number of fixtures found\n",
    "    \n",
    "    # Loop through each fixture and extract details\n",
    "    for fixture in fixtures:\n",
    "        print(\"Fixture:\", fixture)  # Print the fixture element to inspect its structure\n",
    "        \n",
    "        series = fixture.find(\"p\", class_=\"fixture__additional-info\").text.strip()\n",
    "        place = fixture.find(\"span\", class_=\"fixture__additional-info\").text.strip()\n",
    "        date = fixture.find(\"span\", class_=\"fixture__datetime\").text.strip()\n",
    "        time = fixture.find(\"span\", class_=\"fixture__datetime\").text.strip()\n",
    "        \n",
    "        print(\"Series:\", series)\n",
    "        print(\"Place:\", place)\n",
    "        print(\"Date:\", date)\n",
    "        print(\"Time:\", time)\n",
    "        print()\n",
    "else:\n",
    "    print(\"Failed to fetch international fixtures page.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d0124",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/ \n",
    "You have to find following details: A) Rank \n",
    "B) State \n",
    "C) GSDP(18-19)- at current prices \n",
    "D) GSDP(19-20)- at current prices \n",
    "E) Share(18-19) \n",
    "F) GDP($ billion) \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c89af4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 1\n",
      "State: Maharashtra\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): -\n",
      "Share(18-19): 3,108,022\n",
      "GDP($ billion): 13.17%\n",
      "\n",
      "Rank: 2\n",
      "State: Tamil Nadu\n",
      "GSDP(18-19): 2,700,109\n",
      "GSDP(19-20): 2,364,514\n",
      "Share(18-19): 2,071,286\n",
      "GDP($ billion): 8.78%\n",
      "\n",
      "Rank: 3\n",
      "State: Karnataka\n",
      "GSDP(18-19): 2,500,733\n",
      "GSDP(19-20): 2,269,995\n",
      "Share(18-19): 1,978,094\n",
      "GDP($ billion): 8.38%\n",
      "\n",
      "Rank: 4\n",
      "State: Uttar Pradesh\n",
      "GSDP(18-19): 2,547,861\n",
      "GSDP(19-20): 2,258,040\n",
      "Share(18-19): 1,975,595\n",
      "GDP($ billion): 8.37%\n",
      "\n",
      "Rank: 5\n",
      "State: Gujarat\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): 2,230,609\n",
      "Share(18-19): 1,928,683\n",
      "GDP($ billion): 8.17%\n",
      "\n",
      "Rank: 6\n",
      "State: West Bengal\n",
      "GSDP(18-19): 1,700,939\n",
      "GSDP(19-20): 1,531,758\n",
      "Share(18-19): 1,329,238\n",
      "GDP($ billion): 5.63%\n",
      "\n",
      "Rank: 7\n",
      "State: Rajasthan\n",
      "GSDP(18-19): 1,524,030\n",
      "GSDP(19-20): 1,365,849\n",
      "Share(18-19): 1,193,489\n",
      "GDP($ billion): 5.06%\n",
      "\n",
      "Rank: 8\n",
      "State: Andhra Pradesh\n",
      "GSDP(18-19): 1,439,674\n",
      "GSDP(19-20): 1,303,524\n",
      "Share(18-19): 1,148,471\n",
      "GDP($ billion): 4.87%\n",
      "\n",
      "Rank: 9\n",
      "State: Telangana\n",
      "GSDP(18-19): 1,463,960\n",
      "GSDP(19-20): 1,308,034\n",
      "Share(18-19): 1,124,204\n",
      "GDP($ billion): 4.76%\n",
      "\n",
      "Rank: 10\n",
      "State: Madhya Pradesh\n",
      "GSDP(18-19): 1,363,327\n",
      "GSDP(19-20): 1,246,471\n",
      "Share(18-19): 1,092,964\n",
      "GDP($ billion): 4.63%\n",
      "\n",
      "Rank: 11\n",
      "State: Kerala\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): 1,046,188\n",
      "Share(18-19): 934,542\n",
      "GDP($ billion): 3.96%\n",
      "\n",
      "Rank: 12\n",
      "State: Delhi\n",
      "GSDP(18-19): 1,107,746\n",
      "GSDP(19-20): 1,014,688\n",
      "Share(18-19): 881,336\n",
      "GDP($ billion): 3.73%\n",
      "\n",
      "Rank: 13\n",
      "State: Haryana\n",
      "GSDP(18-19): 1,095,535\n",
      "GSDP(19-20): 984,055\n",
      "Share(18-19): 868,905\n",
      "GDP($ billion): 3.68%\n",
      "\n",
      "Rank: 14\n",
      "State: Odisha\n",
      "GSDP(18-19): 832,790\n",
      "GSDP(19-20): 753,177\n",
      "Share(18-19): 662,886\n",
      "GDP($ billion): 2.81%\n",
      "\n",
      "Rank: 15\n",
      "State: Bihar\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): 751,396\n",
      "Share(18-19): 650,302\n",
      "GDP($ billion): 2.76%\n",
      "\n",
      "Rank: 16\n",
      "State: Punjab\n",
      "GSDP(18-19): 736,423\n",
      "GSDP(19-20): 676,164\n",
      "Share(18-19): 617,192\n",
      "GDP($ billion): 2.62%\n",
      "\n",
      "Rank: 17\n",
      "State: Assam\n",
      "GSDP(18-19): 565,401\n",
      "GSDP(19-20): 493,167\n",
      "Share(18-19): 411,454\n",
      "GDP($ billion): 1.74%\n",
      "\n",
      "Rank: 18\n",
      "State: Chhattisgarh\n",
      "GSDP(18-19): 505,887\n",
      "GSDP(19-20): 464,399\n",
      "Share(18-19): 410,525\n",
      "GDP($ billion): 1.74%\n",
      "\n",
      "Rank: 19\n",
      "State: Jharkhand\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): 393,722\n",
      "Share(18-19): 358,863\n",
      "GDP($ billion): 1.52%\n",
      "\n",
      "Rank: 20\n",
      "State: Uttarakhand\n",
      "GSDP(18-19): 346,206\n",
      "GSDP(19-20): 303,781\n",
      "Share(18-19): 267,143\n",
      "GDP($ billion): 1.13%\n",
      "\n",
      "Rank: 21\n",
      "State: Jammu & Kashmir\n",
      "GSDP(18-19): 246,465\n",
      "GSDP(19-20): 224,226\n",
      "Share(18-19): 193,352\n",
      "GDP($ billion): 0.82%\n",
      "\n",
      "Rank: 22\n",
      "State: Himachal Pradesh\n",
      "GSDP(18-19): 207,430\n",
      "GSDP(19-20): 191,728\n",
      "Share(18-19): 172,162\n",
      "GDP($ billion): 0.73%\n",
      "\n",
      "Rank: 23\n",
      "State: Goa\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): 93,672\n",
      "Share(18-19): 84,266\n",
      "GDP($ billion): 0.36%\n",
      "\n",
      "Rank: 24\n",
      "State: Tripura\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): 72,636\n",
      "Share(18-19): 62,550\n",
      "GDP($ billion): 0.27%\n",
      "\n",
      "Rank: 25\n",
      "State: Chandigarh\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): 54,285\n",
      "Share(18-19): 46,096\n",
      "GDP($ billion): 0.20%\n",
      "\n",
      "Rank: 26\n",
      "State: Puducherry\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): 49,643\n",
      "Share(18-19): 43,810\n",
      "GDP($ billion): 0.19%\n",
      "\n",
      "Rank: 27\n",
      "State: Meghalaya\n",
      "GSDP(18-19): 47,381\n",
      "GSDP(19-20): 42,697\n",
      "Share(18-19): 38,785\n",
      "GDP($ billion): 0.16%\n",
      "\n",
      "Rank: 28\n",
      "State: Sikkim\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): 42,756\n",
      "Share(18-19): 37,557\n",
      "GDP($ billion): 0.16%\n",
      "\n",
      "Rank: 29\n",
      "State: Manipur\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): -\n",
      "Share(18-19): 36,594\n",
      "GDP($ billion): 0.16%\n",
      "\n",
      "Rank: 30\n",
      "State: Arunachal Pradesh\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): 39,630\n",
      "Share(18-19): 34,775\n",
      "GDP($ billion): 0.15%\n",
      "\n",
      "Rank: 31\n",
      "State: Nagaland\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): 35,643\n",
      "Share(18-19): 31,038\n",
      "GDP($ billion): 0.13%\n",
      "\n",
      "Rank: 32\n",
      "State: Mizoram\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): -\n",
      "Share(18-19): 27,824\n",
      "GDP($ billion): 0.12%\n",
      "\n",
      "Rank: 33\n",
      "State: Andaman & Nicobar Islands\n",
      "GSDP(18-19): -\n",
      "GSDP(19-20): -\n",
      "Share(18-19): 10,371\n",
      "GDP($ billion): 0.04%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_statewise_gdp(url):\n",
    "    try:\n",
    "        # Step 1: Visit the State-wise GDP of India page\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad status codes\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Step 2: Scrape the required details\n",
    "        table = soup.find(\"table\", class_=\"display\").find(\"tbody\")\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            columns = row.find_all(\"td\")\n",
    "            rank = columns[0].text.strip()\n",
    "            state = columns[1].text.strip()\n",
    "            gdp_18_19 = columns[2].text.strip()\n",
    "            gdp_19_20 = columns[3].text.strip()\n",
    "            share_18_19 = columns[4].text.strip()\n",
    "            gdp_billion = columns[5].text.strip()\n",
    "            print(f\"Rank: {rank}\\nState: {state}\\nGSDP(18-19): {gdp_18_19}\\nGSDP(19-20): {gdp_19_20}\\nShare(18-19): {share_18_19}\\nGDP($ billion): {gdp_billion}\\n\")\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred during the request: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")\n",
    "\n",
    "url = \"https://statisticstimes.com/economy/india/indian-states-gdp.php\"\n",
    "scrape_statewise_gdp(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6338bf1",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/ \n",
    "You have to find the following details: \n",
    "A) Repository title \n",
    "B) Repository description \n",
    "C) Contributors count \n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e9557238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Rust\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Go\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Jupyter Notebook\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Rust\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: TypeScript\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Lua\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Shell\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Go\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Python\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Objective-C\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: CSS\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Python\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: HTML\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Python\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Unknown\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: JavaScript\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Unknown\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Shell\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Unknown\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: TypeScript\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Jupyter Notebook\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: TypeScript\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Zig\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: JavaScript\n",
      "\n",
      "Repository Title: No title found\n",
      "Repository Description: No description found\n",
      "Contributors Count: Unknown\n",
      "Language Used: Jupyter Notebook\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_trending_repositories():\n",
    "    try:\n",
    "        # URL of the GitHub trending repositories page\n",
    "        url = \"https://github.com/trending\"\n",
    "        \n",
    "        # Send a GET request to the trending repositories page and parse the HTML content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad status codes\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Find all repository elements on the trending repositories page\n",
    "        repositories = soup.find_all(\"article\", class_=\"Box-row\")\n",
    "        \n",
    "        # Loop through each repository and extract the required information\n",
    "        for repo in repositories:\n",
    "            # Repository title\n",
    "            title_elem = repo.find(\"h1\", class_=\"h3 lh-condensed\")\n",
    "            title = title_elem.text.strip() if title_elem else \"No title found\"\n",
    "            \n",
    "            # Repository description\n",
    "            description_elem = repo.find(\"p\", class_=\"col-9 color-text-secondary my-1 pr-4\")\n",
    "            description = description_elem.text.strip() if description_elem else \"No description found\"\n",
    "            \n",
    "            # Contributors count\n",
    "            contributors_count_elem = repo.find(\"a\", class_=\"Link--muted d-inline-block mr-3\")\n",
    "            contributors_count = contributors_count_elem.text.strip() if contributors_count_elem else \"Unknown\"\n",
    "            \n",
    "            # Language used\n",
    "            language_elem = repo.find(\"span\", itemprop=\"programmingLanguage\")\n",
    "            language = language_elem.text.strip() if language_elem else \"Unknown\"\n",
    "            \n",
    "            # Print the extracted information\n",
    "            print(\"Repository Title:\", title)\n",
    "            print(\"Repository Description:\", description)\n",
    "            print(\"Contributors Count:\", contributors_count)\n",
    "            print(\"Language Used:\", language)\n",
    "            print()\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred during the request: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")\n",
    "\n",
    "# Call the function to scrape trending repositories\n",
    "scrape_trending_repositories()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e01d9",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the \n",
    "following details: \n",
    "A) Song name \n",
    "B) Artist name \n",
    "C) Last week rank \n",
    "D) Peak rank \n",
    "E) Weeks on board \n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a25726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf77eded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to billboard_hot_100.csv\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Hot 100 page\n",
    "url = 'https://www.billboard.com/charts/hot-100'\n",
    "\n",
    "# Open the URL and get the HTML content\n",
    "html = urlopen(url).read()\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find all the containers that hold information about the top 100 songs\n",
    "containers = soup.find_all('li', class_='chart-list__element')\n",
    "\n",
    "# Create a CSV file to save the data\n",
    "filename = 'billboard_hot_100.csv'\n",
    "with open(filename, 'w') as f:\n",
    "    # Write the header row\n",
    "    f.write('Song, Artist, Last Week, Peak Position, Weeks on Chart\\n')\n",
    "\n",
    "    # Loop through each container and extract song details\n",
    "    for container in containers:\n",
    "        # Extract song name\n",
    "        song = container.find('span', class_='chart-element__information__song').get_text().strip()\n",
    "\n",
    "        # Extract artist name\n",
    "        artist = container.find('span', class_='chart-element__information__artist').get_text().strip()\n",
    "\n",
    "        # Extract last week's rank\n",
    "        last_week = container.find('div', class_='chart-element__meta text--center color--secondary text--last').get_text().strip()\n",
    "\n",
    "        # Extract peak position\n",
    "        peak_position = container.find('div', class_='chart-element__meta text--center color--secondary text--peak').get_text().strip()\n",
    "\n",
    "        # Extract weeks on chart\n",
    "        weeks_on_chart = container.find('div', class_='chart-element__meta text--center color--secondary text--week').get_text().strip()\n",
    "\n",
    "        # Write the song details to the CSV file\n",
    "        f.write(f'\"{song}\",\"{artist}\",\"{last_week}\",\"{peak_position}\",\"{weeks_on_chart}\"\\n')\n",
    "\n",
    "print('Data scraped and saved to', filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3419ace",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels. \n",
    "A) Book name \n",
    "B) Author name \n",
    "C) Volumes sold \n",
    "D) Publisher \n",
    "E) Genre \n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "96e5d879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Name: 1\n",
      "Author Name: Da Vinci Code,The\n",
      "Volumes Sold: Brown, Dan\n",
      "Publisher: 5,094,805\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 2\n",
      "Author Name: Harry Potter and the Deathly Hallows\n",
      "Volumes Sold: Rowling, J.K.\n",
      "Publisher: 4,475,152\n",
      "Genre: Bloomsbury\n",
      "-----------------------------\n",
      "Book Name: 3\n",
      "Author Name: Harry Potter and the Philosopher's Stone\n",
      "Volumes Sold: Rowling, J.K.\n",
      "Publisher: 4,200,654\n",
      "Genre: Bloomsbury\n",
      "-----------------------------\n",
      "Book Name: 4\n",
      "Author Name: Harry Potter and the Order of the Phoenix\n",
      "Volumes Sold: Rowling, J.K.\n",
      "Publisher: 4,179,479\n",
      "Genre: Bloomsbury\n",
      "-----------------------------\n",
      "Book Name: 5\n",
      "Author Name: Fifty Shades of Grey\n",
      "Volumes Sold: James, E. L.\n",
      "Publisher: 3,758,936\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 6\n",
      "Author Name: Harry Potter and the Goblet of Fire\n",
      "Volumes Sold: Rowling, J.K.\n",
      "Publisher: 3,583,215\n",
      "Genre: Bloomsbury\n",
      "-----------------------------\n",
      "Book Name: 7\n",
      "Author Name: Harry Potter and the Chamber of Secrets\n",
      "Volumes Sold: Rowling, J.K.\n",
      "Publisher: 3,484,047\n",
      "Genre: Bloomsbury\n",
      "-----------------------------\n",
      "Book Name: 8\n",
      "Author Name: Harry Potter and the Prisoner of Azkaban\n",
      "Volumes Sold: Rowling, J.K.\n",
      "Publisher: 3,377,906\n",
      "Genre: Bloomsbury\n",
      "-----------------------------\n",
      "Book Name: 9\n",
      "Author Name: Angels and Demons\n",
      "Volumes Sold: Brown, Dan\n",
      "Publisher: 3,193,946\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 10\n",
      "Author Name: Harry Potter and the Half-blood Prince:Children's Edition\n",
      "Volumes Sold: Rowling, J.K.\n",
      "Publisher: 2,950,264\n",
      "Genre: Bloomsbury\n",
      "-----------------------------\n",
      "Book Name: 11\n",
      "Author Name: Fifty Shades Darker\n",
      "Volumes Sold: James, E. L.\n",
      "Publisher: 2,479,784\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 12\n",
      "Author Name: Twilight\n",
      "Volumes Sold: Meyer, Stephenie\n",
      "Publisher: 2,315,405\n",
      "Genre: Little, Brown Book\n",
      "-----------------------------\n",
      "Book Name: 13\n",
      "Author Name: Girl with the Dragon Tattoo,The:Millennium Trilogy\n",
      "Volumes Sold: Larsson, Stieg\n",
      "Publisher: 2,233,570\n",
      "Genre: Quercus\n",
      "-----------------------------\n",
      "Book Name: 14\n",
      "Author Name: Fifty Shades Freed\n",
      "Volumes Sold: James, E. L.\n",
      "Publisher: 2,193,928\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 15\n",
      "Author Name: Lost Symbol,The\n",
      "Volumes Sold: Brown, Dan\n",
      "Publisher: 2,183,031\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 16\n",
      "Author Name: New Moon\n",
      "Volumes Sold: Meyer, Stephenie\n",
      "Publisher: 2,152,737\n",
      "Genre: Little, Brown Book\n",
      "-----------------------------\n",
      "Book Name: 17\n",
      "Author Name: Deception Point\n",
      "Volumes Sold: Brown, Dan\n",
      "Publisher: 2,062,145\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 18\n",
      "Author Name: Eclipse\n",
      "Volumes Sold: Meyer, Stephenie\n",
      "Publisher: 2,052,876\n",
      "Genre: Little, Brown Book\n",
      "-----------------------------\n",
      "Book Name: 19\n",
      "Author Name: Lovely Bones,The\n",
      "Volumes Sold: Sebold, Alice\n",
      "Publisher: 2,005,598\n",
      "Genre: Pan Macmillan\n",
      "-----------------------------\n",
      "Book Name: 20\n",
      "Author Name: Curious Incident of the Dog in the Night-time,The\n",
      "Volumes Sold: Haddon, Mark\n",
      "Publisher: 1,979,552\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 21\n",
      "Author Name: Digital Fortress\n",
      "Volumes Sold: Brown, Dan\n",
      "Publisher: 1,928,900\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 22\n",
      "Author Name: Short History of Nearly Everything,A\n",
      "Volumes Sold: Bryson, Bill\n",
      "Publisher: 1,852,919\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 23\n",
      "Author Name: Girl Who Played with Fire,The:Millennium Trilogy\n",
      "Volumes Sold: Larsson, Stieg\n",
      "Publisher: 1,814,784\n",
      "Genre: Quercus\n",
      "-----------------------------\n",
      "Book Name: 24\n",
      "Author Name: Breaking Dawn\n",
      "Volumes Sold: Meyer, Stephenie\n",
      "Publisher: 1,787,118\n",
      "Genre: Little, Brown Book\n",
      "-----------------------------\n",
      "Book Name: 25\n",
      "Author Name: Very Hungry Caterpillar,The:The Very Hungry Caterpillar\n",
      "Volumes Sold: Carle, Eric\n",
      "Publisher: 1,783,535\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 26\n",
      "Author Name: Gruffalo,The\n",
      "Volumes Sold: Donaldson, Julia\n",
      "Publisher: 1,781,269\n",
      "Genre: Pan Macmillan\n",
      "-----------------------------\n",
      "Book Name: 27\n",
      "Author Name: Jamie's 30-Minute Meals\n",
      "Volumes Sold: Oliver, Jamie\n",
      "Publisher: 1,743,266\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 28\n",
      "Author Name: Kite Runner,The\n",
      "Volumes Sold: Hosseini, Khaled\n",
      "Publisher: 1,629,119\n",
      "Genre: Bloomsbury\n",
      "-----------------------------\n",
      "Book Name: 29\n",
      "Author Name: One Day\n",
      "Volumes Sold: Nicholls, David\n",
      "Publisher: 1,616,068\n",
      "Genre: Hodder & Stoughton\n",
      "-----------------------------\n",
      "Book Name: 30\n",
      "Author Name: Thousand Splendid Suns,A\n",
      "Volumes Sold: Hosseini, Khaled\n",
      "Publisher: 1,583,992\n",
      "Genre: Bloomsbury\n",
      "-----------------------------\n",
      "Book Name: 31\n",
      "Author Name: Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\n",
      "Volumes Sold: Larsson, Stieg\n",
      "Publisher: 1,555,135\n",
      "Genre: Quercus\n",
      "-----------------------------\n",
      "Book Name: 32\n",
      "Author Name: Time Traveler's Wife,The\n",
      "Volumes Sold: Niffenegger, Audrey\n",
      "Publisher: 1,546,886\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 33\n",
      "Author Name: Atonement\n",
      "Volumes Sold: McEwan, Ian\n",
      "Publisher: 1,539,428\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 34\n",
      "Author Name: Bridget Jones's Diary:A Novel\n",
      "Volumes Sold: Fielding, Helen\n",
      "Publisher: 1,508,205\n",
      "Genre: Pan Macmillan\n",
      "-----------------------------\n",
      "Book Name: 35\n",
      "Author Name: World According to Clarkson,The\n",
      "Volumes Sold: Clarkson, Jeremy\n",
      "Publisher: 1,489,403\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 36\n",
      "Author Name: Captain Corelli's Mandolin\n",
      "Volumes Sold: Bernieres, Louis de\n",
      "Publisher: 1,352,318\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 37\n",
      "Author Name: Sound of Laughter,The\n",
      "Volumes Sold: Kay, Peter\n",
      "Publisher: 1,310,207\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 38\n",
      "Author Name: Life of Pi\n",
      "Volumes Sold: Martel, Yann\n",
      "Publisher: 1,310,176\n",
      "Genre: Canongate\n",
      "-----------------------------\n",
      "Book Name: 39\n",
      "Author Name: Billy Connolly\n",
      "Volumes Sold: Stephenson, Pamela\n",
      "Publisher: 1,231,957\n",
      "Genre: HarperCollins\n",
      "-----------------------------\n",
      "Book Name: 40\n",
      "Author Name: Child Called It,A\n",
      "Volumes Sold: Pelzer, Dave\n",
      "Publisher: 1,217,712\n",
      "Genre: Orion\n",
      "-----------------------------\n",
      "Book Name: 41\n",
      "Author Name: Gruffalo's Child,The\n",
      "Volumes Sold: Donaldson, Julia\n",
      "Publisher: 1,208,711\n",
      "Genre: Pan Macmillan\n",
      "-----------------------------\n",
      "Book Name: 42\n",
      "Author Name: Angela's Ashes:A Memoir of a Childhood\n",
      "Volumes Sold: McCourt, Frank\n",
      "Publisher: 1,204,058\n",
      "Genre: HarperCollins\n",
      "-----------------------------\n",
      "Book Name: 43\n",
      "Author Name: Birdsong\n",
      "Volumes Sold: Faulks, Sebastian\n",
      "Publisher: 1,184,967\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 44\n",
      "Author Name: Northern Lights:His Dark Materials S.\n",
      "Volumes Sold: Pullman, Philip\n",
      "Publisher: 1,181,503\n",
      "Genre: Scholastic Ltd.\n",
      "-----------------------------\n",
      "Book Name: 45\n",
      "Author Name: Labyrinth\n",
      "Volumes Sold: Mosse, Kate\n",
      "Publisher: 1,181,093\n",
      "Genre: Orion\n",
      "-----------------------------\n",
      "Book Name: 46\n",
      "Author Name: Harry Potter and the Half-blood Prince\n",
      "Volumes Sold: Rowling, J.K.\n",
      "Publisher: 1,153,181\n",
      "Genre: Bloomsbury\n",
      "-----------------------------\n",
      "Book Name: 47\n",
      "Author Name: Help,The\n",
      "Volumes Sold: Stockett, Kathryn\n",
      "Publisher: 1,132,336\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 48\n",
      "Author Name: Man and Boy\n",
      "Volumes Sold: Parsons, Tony\n",
      "Publisher: 1,130,802\n",
      "Genre: HarperCollins\n",
      "-----------------------------\n",
      "Book Name: 49\n",
      "Author Name: Memoirs of a Geisha\n",
      "Volumes Sold: Golden, Arthur\n",
      "Publisher: 1,126,337\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 50\n",
      "Author Name: No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\n",
      "Volumes Sold: McCall Smith, Alexander\n",
      "Publisher: 1,115,549\n",
      "Genre: Little, Brown Book\n",
      "-----------------------------\n",
      "Book Name: 51\n",
      "Author Name: Island,The\n",
      "Volumes Sold: Hislop, Victoria\n",
      "Publisher: 1,108,328\n",
      "Genre: Headline\n",
      "-----------------------------\n",
      "Book Name: 52\n",
      "Author Name: PS, I Love You\n",
      "Volumes Sold: Ahern, Cecelia\n",
      "Publisher: 1,107,379\n",
      "Genre: HarperCollins\n",
      "-----------------------------\n",
      "Book Name: 53\n",
      "Author Name: You are What You Eat:The Plan That Will Change Your Life\n",
      "Volumes Sold: McKeith, Gillian\n",
      "Publisher: 1,104,403\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 54\n",
      "Author Name: Shadow of the Wind,The\n",
      "Volumes Sold: Zafon, Carlos Ruiz\n",
      "Publisher: 1,092,349\n",
      "Genre: Orion\n",
      "-----------------------------\n",
      "Book Name: 55\n",
      "Author Name: Tales of Beedle the Bard,The\n",
      "Volumes Sold: Rowling, J.K.\n",
      "Publisher: 1,090,847\n",
      "Genre: Bloomsbury\n",
      "-----------------------------\n",
      "Book Name: 56\n",
      "Author Name: Broker,The\n",
      "Volumes Sold: Grisham, John\n",
      "Publisher: 1,087,262\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 57\n",
      "Author Name: Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\n",
      "Volumes Sold: Atkins, Robert C.\n",
      "Publisher: 1,054,196\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 58\n",
      "Author Name: Subtle Knife,The:His Dark Materials S.\n",
      "Volumes Sold: Pullman, Philip\n",
      "Publisher: 1,037,160\n",
      "Genre: Scholastic Ltd.\n",
      "-----------------------------\n",
      "Book Name: 59\n",
      "Author Name: Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation\n",
      "Volumes Sold: Truss, Lynne\n",
      "Publisher: 1,023,688\n",
      "Genre: Profile Books Group\n",
      "-----------------------------\n",
      "Book Name: 60\n",
      "Author Name: Delia's How to Cook:(Bk.1)\n",
      "Volumes Sold: Smith, Delia\n",
      "Publisher: 1,015,956\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 61\n",
      "Author Name: Chocolat\n",
      "Volumes Sold: Harris, Joanne\n",
      "Publisher: 1,009,873\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 62\n",
      "Author Name: Boy in the Striped Pyjamas,The\n",
      "Volumes Sold: Boyne, John\n",
      "Publisher: 1,004,414\n",
      "Genre: Random House Childrens Books G\n",
      "-----------------------------\n",
      "Book Name: 63\n",
      "Author Name: My Sister's Keeper\n",
      "Volumes Sold: Picoult, Jodi\n",
      "Publisher: 1,003,780\n",
      "Genre: Hodder & Stoughton\n",
      "-----------------------------\n",
      "Book Name: 64\n",
      "Author Name: Amber Spyglass,The:His Dark Materials S.\n",
      "Volumes Sold: Pullman, Philip\n",
      "Publisher: 1,002,314\n",
      "Genre: Scholastic Ltd.\n",
      "-----------------------------\n",
      "Book Name: 65\n",
      "Author Name: To Kill a Mockingbird\n",
      "Volumes Sold: Lee, Harper\n",
      "Publisher: 998,213\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 66\n",
      "Author Name: Men are from Mars, Women are from Venus:A Practical Guide for Improvin\n",
      "Volumes Sold: Gray, John\n",
      "Publisher: 992,846\n",
      "Genre: HarperCollins\n",
      "-----------------------------\n",
      "Book Name: 67\n",
      "Author Name: Dear Fatty\n",
      "Volumes Sold: French, Dawn\n",
      "Publisher: 986,753\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 68\n",
      "Author Name: Short History of Tractors in Ukrainian,A\n",
      "Volumes Sold: Lewycka, Marina\n",
      "Publisher: 986,115\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 69\n",
      "Author Name: Hannibal\n",
      "Volumes Sold: Harris, Thomas\n",
      "Publisher: 970,509\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 70\n",
      "Author Name: Lord of the Rings,The\n",
      "Volumes Sold: Tolkien, J. R. R.\n",
      "Publisher: 967,466\n",
      "Genre: HarperCollins\n",
      "-----------------------------\n",
      "Book Name: 71\n",
      "Author Name: Stupid White Men:...and Other Sorry Excuses for the State of the Natio\n",
      "Volumes Sold: Moore, Michael\n",
      "Publisher: 963,353\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 72\n",
      "Author Name: Interpretation of Murder,The\n",
      "Volumes Sold: Rubenfeld, Jed\n",
      "Publisher: 962,515\n",
      "Genre: Headline\n",
      "-----------------------------\n",
      "Book Name: 73\n",
      "Author Name: Sharon Osbourne Extreme:My Autobiography\n",
      "Volumes Sold: Osbourne, Sharon\n",
      "Publisher: 959,496\n",
      "Genre: Little, Brown Book\n",
      "-----------------------------\n",
      "Book Name: 74\n",
      "Author Name: Alchemist,The:A Fable About Following Your Dream\n",
      "Volumes Sold: Coelho, Paulo\n",
      "Publisher: 956,114\n",
      "Genre: HarperCollins\n",
      "-----------------------------\n",
      "Book Name: 75\n",
      "Author Name: At My Mother's Knee ...:and Other Low Joints\n",
      "Volumes Sold: O'Grady, Paul\n",
      "Publisher: 945,640\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 76\n",
      "Author Name: Notes from a Small Island\n",
      "Volumes Sold: Bryson, Bill\n",
      "Publisher: 931,312\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 77\n",
      "Author Name: Return of the Naked Chef,The\n",
      "Volumes Sold: Oliver, Jamie\n",
      "Publisher: 925,425\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 78\n",
      "Author Name: Bridget Jones: The Edge of Reason\n",
      "Volumes Sold: Fielding, Helen\n",
      "Publisher: 924,695\n",
      "Genre: Pan Macmillan\n",
      "-----------------------------\n",
      "Book Name: 79\n",
      "Author Name: Jamie's Italy\n",
      "Volumes Sold: Oliver, Jamie\n",
      "Publisher: 906,968\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 80\n",
      "Author Name: I Can Make You Thin\n",
      "Volumes Sold: McKenna, Paul\n",
      "Publisher: 905,086\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 81\n",
      "Author Name: Down Under\n",
      "Volumes Sold: Bryson, Bill\n",
      "Publisher: 890,847\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 82\n",
      "Author Name: Summons,The\n",
      "Volumes Sold: Grisham, John\n",
      "Publisher: 869,671\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 83\n",
      "Author Name: Small Island\n",
      "Volumes Sold: Levy, Andrea\n",
      "Publisher: 869,659\n",
      "Genre: Headline\n",
      "-----------------------------\n",
      "Book Name: 84\n",
      "Author Name: Nigella Express\n",
      "Volumes Sold: Lawson, Nigella\n",
      "Publisher: 862,602\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 85\n",
      "Author Name: Brick Lane\n",
      "Volumes Sold: Ali, Monica\n",
      "Publisher: 856,540\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 86\n",
      "Author Name: Memory Keeper's Daughter,The\n",
      "Volumes Sold: Edwards, Kim\n",
      "Publisher: 845,858\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 87\n",
      "Author Name: Room on the Broom\n",
      "Volumes Sold: Donaldson, Julia\n",
      "Publisher: 842,535\n",
      "Genre: Pan Macmillan\n",
      "-----------------------------\n",
      "Book Name: 88\n",
      "Author Name: About a Boy\n",
      "Volumes Sold: Hornby, Nick\n",
      "Publisher: 828,215\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 89\n",
      "Author Name: My Booky Wook\n",
      "Volumes Sold: Brand, Russell\n",
      "Publisher: 820,563\n",
      "Genre: Hodder & Stoughton\n",
      "-----------------------------\n",
      "Book Name: 90\n",
      "Author Name: God Delusion,The\n",
      "Volumes Sold: Dawkins, Richard\n",
      "Publisher: 816,907\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 91\n",
      "Author Name: \"Beano\" Annual,The\n",
      "Volumes Sold: 0\n",
      "Publisher: 816,585\n",
      "Genre: D.C. Thomson\n",
      "-----------------------------\n",
      "Book Name: 92\n",
      "Author Name: White Teeth\n",
      "Volumes Sold: Smith, Zadie\n",
      "Publisher: 815,586\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 93\n",
      "Author Name: House at Riverton,The\n",
      "Volumes Sold: Morton, Kate\n",
      "Publisher: 814,370\n",
      "Genre: Pan Macmillan\n",
      "-----------------------------\n",
      "Book Name: 94\n",
      "Author Name: Book Thief,The\n",
      "Volumes Sold: Zusak, Markus\n",
      "Publisher: 809,641\n",
      "Genre: Transworld\n",
      "-----------------------------\n",
      "Book Name: 95\n",
      "Author Name: Nights of Rain and Stars\n",
      "Volumes Sold: Binchy, Maeve\n",
      "Publisher: 808,900\n",
      "Genre: Orion\n",
      "-----------------------------\n",
      "Book Name: 96\n",
      "Author Name: Ghost,The\n",
      "Volumes Sold: Harris, Robert\n",
      "Publisher: 807,311\n",
      "Genre: Random House\n",
      "-----------------------------\n",
      "Book Name: 97\n",
      "Author Name: Happy Days with the Naked Chef\n",
      "Volumes Sold: Oliver, Jamie\n",
      "Publisher: 794,201\n",
      "Genre: Penguin\n",
      "-----------------------------\n",
      "Book Name: 98\n",
      "Author Name: Hunger Games,The:Hunger Games Trilogy\n",
      "Volumes Sold: Collins, Suzanne\n",
      "Publisher: 792,187\n",
      "Genre: Scholastic Ltd.\n",
      "-----------------------------\n",
      "Book Name: 99\n",
      "Author Name: Lost Boy,The:A Foster Child's Search for the Love of a Family\n",
      "Volumes Sold: Pelzer, Dave\n",
      "Publisher: 791,507\n",
      "Genre: Orion\n",
      "-----------------------------\n",
      "Book Name: 100\n",
      "Author Name: Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\n",
      "Volumes Sold: Oliver, Jamie\n",
      "Publisher: 791,095\n",
      "Genre: Penguin\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the details of highest-selling novels\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "book_names = []\n",
    "author_names = []\n",
    "volumes_sold = []\n",
    "publishers = []\n",
    "genres = []\n",
    "\n",
    "# Loop through each row of the table (excluding the header row)\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    # Extract data from each column of the row\n",
    "    columns = row.find_all(\"td\")\n",
    "    \n",
    "    # Ensure that there are enough columns\n",
    "    if len(columns) >= 5:\n",
    "        book_names.append(columns[0].text.strip())\n",
    "        author_names.append(columns[1].text.strip())\n",
    "        volumes_sold.append(columns[2].text.strip())\n",
    "        publishers.append(columns[3].text.strip())\n",
    "        genres.append(columns[4].text.strip())\n",
    "\n",
    "# Print or store the scraped data\n",
    "for i in range(len(book_names)):\n",
    "    print(\"Book Name:\", book_names[i])\n",
    "    print(\"Author Name:\", author_names[i])\n",
    "    print(\"Volumes Sold:\", volumes_sold[i])\n",
    "    print(\"Publisher:\", publishers[i])\n",
    "    print(\"Genre:\", genres[i])\n",
    "    print(\"-----------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb5135",
   "metadata": {},
   "source": [
    " \n",
    "8. Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/ You \n",
    "have to find the following details: \n",
    "A) Dataset name \n",
    "B) Data type \n",
    "C) Task \n",
    "D) Attribute type \n",
    "E) No of instances \n",
    "F) No of attribute G) Year \n",
    " Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fac9704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to 'View ALL Data Sets' not found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Visit the UCI Machine Learning Repository homepage\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Step 2: Navigate to the \"View All Data Sets\" page\n",
    "    all_datasets_link = soup.find('a', href='/datasets.php')\n",
    "    if all_datasets_link:\n",
    "        all_datasets_url = url + all_datasets_link['href']\n",
    "\n",
    "        # Step 3: Scrape the details of each dataset\n",
    "        response = requests.get(all_datasets_url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Find the table containing dataset details\n",
    "            table = soup.find('table')\n",
    "\n",
    "            # Initialize lists to store dataset details\n",
    "            dataset_names = []\n",
    "            data_types = []\n",
    "            tasks = []\n",
    "            attribute_types = []\n",
    "            num_instances = []\n",
    "            num_attributes = []\n",
    "            years = []\n",
    "\n",
    "            # Extract data from each row of the table\n",
    "            rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "            for row in rows:\n",
    "                columns = row.find_all('td')\n",
    "\n",
    "                dataset_names.append(columns[0].text.strip())\n",
    "                data_types.append(columns[1].text.strip())\n",
    "                tasks.append(columns[2].text.strip())\n",
    "                attribute_types.append(columns[3].text.strip())\n",
    "                num_instances.append(columns[4].text.strip())\n",
    "                num_attributes.append(columns[5].text.strip())\n",
    "                years.append(columns[6].text.strip())\n",
    "\n",
    "            # Print the details of each dataset\n",
    "            for i in range(len(dataset_names)):\n",
    "                print(\"Dataset Name:\", dataset_names[i])\n",
    "                print(\"Data Type:\", data_types[i])\n",
    "                print(\"Task:\", tasks[i])\n",
    "                print(\"Attribute Type:\", attribute_types[i])\n",
    "                print(\"No of Instances:\", num_instances[i])\n",
    "                print(\"No of Attributes:\", num_attributes[i])\n",
    "                print(\"Year:\", years[i])\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "        else:\n",
    "            print(\"Failed to fetch View All Data Sets page.\")\n",
    "    else:\n",
    "        print(\"Link to 'View ALL Data Sets' not found.\")\n",
    "else:\n",
    "    print(\"Failed to fetch UCI Machine Learning Repository homepage.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
