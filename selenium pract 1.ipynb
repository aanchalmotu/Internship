{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c922f21",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to\n",
    "scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f50291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install selenium pandas\n",
    "\n",
    "# Import necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up the Selenium webdriver\n",
    "driver = webdriver.Chrome('path_to_chromedriver')  # Replace 'path_to_chromedriver' with the actual path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec973e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the webpage\n",
    "driver.get('https://www.shine.com/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e322d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the job title and location\n",
    "driver.find_element(By.ID, 'id_q').send_keys('Data Analyst')\n",
    "driver.find_element(By.ID, 'id_l').send_keys('Bangalore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8486bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the search button\n",
    "driver.find_element(By.XPATH, '//button[@type=\"submit\"]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2aacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the data for the first 10 job results\n",
    "job_titles = driver.find_elements(By.XPATH, '//a[@class=\"job_title_anchor\"]')\n",
    "job_locations = driver.find_elements(By.XPATH, '//li[@class=\"w-30 mr-10 result-display-location\"]/span')\n",
    "company_names = driver.find_elements(By.XPATH, '//a[@class=\"result-display-company-name\"]')\n",
    "experience_required = driver.find_elements(By.XPATH, '//li[@class=\"w-30 mr-10 result-display-exp\"]/span')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc91779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries for each job\n",
    "data = [{'Job Title': job_titles[i].text,\n",
    "         'Job Location': job_locations[i].text,\n",
    "         'Company Name': company_names[i].text,\n",
    "         'Experience Required': experience_required[i].text}\n",
    "        for i in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0e14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of the scraped data and display\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d65d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the webdriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465c6f8",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for ““Data Scientist” Job position in “Bangalore” location.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to\n",
    "scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd379913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install selenium pandas\n",
    "\n",
    "# Import necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up the Selenium webdriver\n",
    "driver = webdriver.Chrome('path_to_chromedriver')  # Replace 'path_to_chromedriver' with the actual path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd12bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Naukri website\n",
    "driver.get('https://www.naukri.com/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f89378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter job title and location, and click the search button\n",
    "driver.find_element(By.ID, 'qsb-keyword-sugg').send_keys('Data Scientist')\n",
    "driver.find_element(By.ID, 'qsb-location-sugg').send_keys('Bangalore')\n",
    "driver.find_element(By.CLASS_NAME, 'btn').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd401aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data for the first 10 job results\n",
    "job_titles = driver.find_elements(By.XPATH, '//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_locations = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span')\n",
    "company_names = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "experience_required = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')\n",
    "\n",
    "# Create a list of dictionaries for each job\n",
    "data_scientist = [{'Job Title': title.text,\n",
    "                   'Job Location': location.text,\n",
    "                   'Company Name': company.text,\n",
    "                   'Experience Required': experience.text}\n",
    "                  for title, location, company, experience in zip(job_titles, job_locations, company_names, experience_required)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf55121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of the scraped data\n",
    "df_data_scientist = pd.DataFrame(data_scientist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "df_data_scientist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e30852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the webdriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b8c1e",
   "metadata": {},
   "source": [
    "Q3: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search fieldwhere “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100sunglasses. Note: That all of the above steps have to be done\n",
    "by coding only and not manually.\n",
    "Note: That all of the above steps have to be done by coding only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install selenium pandas\n",
    "\n",
    "# Import necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# Set up the Selenium webdriver\n",
    "driver = webdriver.Chrome('path_to_chromedriver')  # Replace 'path_to_chromedriver' with the actual path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a27c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Flipkart website\n",
    "driver.get('https://www.flipkart.com/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for sunglasses\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys('sunglasses')\n",
    "search_box.send_keys(Keys.RETURN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data from the first page\n",
    "brand_list = []\n",
    "description_list = []\n",
    "price_list = []\n",
    "\n",
    "# Wait for a few seconds to ensure the page loads completely\n",
    "time.sleep(3)\n",
    "\n",
    "# Extract data\n",
    "brands = driver.find_elements(By.CLASS_NAME, '_2B_pmu')\n",
    "descriptions = driver.find_elements(By.CLASS_NAME, '_2mylT6')\n",
    "prices = driver.find_elements(By.CLASS_NAME, '_1vC4OE')\n",
    "\n",
    "for brand, description, price in zip(brands, descriptions, prices):\n",
    "    brand_list.append(brand.text)\n",
    "    description_list.append(description.text)\n",
    "    price_list.append(price.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f55326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the \"Next\" button to go to the next page\n",
    "next_button = driver.find_element(By.XPATH, '//a[@class=\"_3fVaIS\"]')\n",
    "next_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data from the next page\n",
    "# Wait for a few seconds to ensure the page loads completely\n",
    "time.sleep(3)\n",
    "\n",
    "# Extract data from the second page\n",
    "brands = driver.find_elements(By.CLASS_NAME, '_2B_pmu')\n",
    "descriptions = driver.find_elements(By.CLASS_NAME, '_2mylT6')\n",
    "prices = driver.find_elements(By.CLASS_NAME, '_1vC4OE')\n",
    "\n",
    "for brand, description, price in zip(brands, descriptions, prices):\n",
    "    brand_list.append(brand.text)\n",
    "    description_list.append(description.text)\n",
    "    price_list.append(price.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405a964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the pages until you get data for 100 sunglasses\n",
    "while len(brand_list) < 100:\n",
    "    # Click on the \"Next\" button\n",
    "    next_button = driver.find_element(By.XPATH, '//a[@class=\"_3fVaIS\"]')\n",
    "    next_button.click()\n",
    "\n",
    "    # Wait for a few seconds to ensure the page loads completely\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Extract data from the current page\n",
    "    brands = driver.find_elements(By.CLASS_NAME, '_2B_pmu')\n",
    "    descriptions = driver.find_elements(By.CLASS_NAME, '_2mylT6')\n",
    "    prices = driver.find_elements(By.CLASS_NAME, '_1vC4OE')\n",
    "\n",
    "    for brand, description, price in zip(brands, descriptions, prices):\n",
    "        brand_list.append(brand.text)\n",
    "        description_list.append(description.text)\n",
    "        price_list.append(price.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a00a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of the scraped data\n",
    "sunglasses_df = pd.DataFrame({\n",
    "    'Brand': brand_list[:100],\n",
    "    'Product Description': description_list[:100],\n",
    "    'Price': price_list[:100]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eee7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "sunglasses_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103a447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the webdriver\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
